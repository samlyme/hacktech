{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519c09a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch imported — version: 2.6.0+cu124\n",
      "✅ CUDA is available.\n",
      "   ‣ CUDA runtime (from wheel): 12.4\n",
      "   ‣ Number of visible GPUs  : 1\n",
      "   ‣ GPU 0 name              : NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "   ‣ Compute capability      : 8.9\n",
      "   ‣ Total memory (GiB)      : 8.0\n"
     ]
    }
   ],
   "source": [
    "def torch_cuda_diagnostics():\n",
    "    try:\n",
    "        import torch\n",
    "    except ImportError:\n",
    "        print(\"❌ PyTorch is NOT installed in this environment.\")\n",
    "        return\n",
    "\n",
    "    print(f\"✅ PyTorch imported — version: {torch.__version__}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"✅ CUDA is available.\")\n",
    "        print(f\"   ‣ CUDA runtime (from wheel): {torch.version.cuda}\")\n",
    "        print(f\"   ‣ Number of visible GPUs  : {torch.cuda.device_count()}\")\n",
    "        # Grab information about the first device\n",
    "        dev = torch.cuda.get_device_properties(0)\n",
    "        print(f\"   ‣ GPU 0 name              : {dev.name}\")\n",
    "        print(f\"   ‣ Compute capability      : {dev.major}.{dev.minor}\")\n",
    "        print(f\"   ‣ Total memory (GiB)      : {dev.total_memory / 2**30:.1f}\")\n",
    "    else:\n",
    "        # Torch loaded, but either no GPU or wrong wheel (CPU-only build)\n",
    "        print(\"⚠️  CUDA NOT available. Possible reasons:\")\n",
    "        print(\"   • No NVIDIA GPU/drivers detected\")\n",
    "        print(\"   • Driver too old for the wheel's CUDA version\")\n",
    "        print(\"   • Installed the CPU-only torch wheel\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch_cuda_diagnostics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792f645",
   "metadata": {},
   "source": [
    "## Download EDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513c2eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00273136  0.00343328  0.00294499 ...  0.00178531 -0.0016022\n",
      " -0.00218204]\n",
      "[0.03254749 0.03282216 0.03334096 ... 0.0142977  0.01350423 0.0127718 ]\n",
      "dict_keys(['EEG A1-A2', 'EEG C3-A2', 'EEG C4-A1', 'EOG LOC-A2', 'EOG ROC-A2', 'EMG Chin', 'Leg 1', 'Leg 2', 'ECG I', 'RR', 'Snore', 'Flow Patient', 'Effort THO', 'Effort ABD', 'SpO2', 'Body', 'PulseRate', 'Mic', 'Tracheal'])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "\n",
    "edf_path = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\\00000995-100507[001].edf\")   # raw-string or forward slashes\n",
    "\n",
    "if not edf_path.exists():\n",
    "    raise FileNotFoundError(edf_path)\n",
    "\n",
    "# 3. Open as before\n",
    "with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "    labels = f.getSignalLabels()\n",
    "    sigbufs = {lbl: f.readSignal(i) for i, lbl in enumerate(labels)}\n",
    "\n",
    "print(sigbufs['Tracheal'])\n",
    "print(sigbufs['Mic'])\n",
    "print(sigbufs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f875f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172800000\n"
     ]
    }
   ],
   "source": [
    "print(sigbufs['Tracheal'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e251a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG A1-A2        Fs = 200.0 Hz\n",
      "EEG C3-A2        Fs = 200.0 Hz\n",
      "EEG C4-A1        Fs = 200.0 Hz\n",
      "EOG LOC-A2       Fs = 200.0 Hz\n",
      "EOG ROC-A2       Fs = 200.0 Hz\n",
      "EMG Chin         Fs = 200.0 Hz\n",
      "Leg 1            Fs = 200.0 Hz\n",
      "Leg 2            Fs = 200.0 Hz\n",
      "ECG I            Fs = 200.0 Hz\n",
      "RR               Fs = 10.0 Hz\n",
      "Snore            Fs = 500.0 Hz\n",
      "Flow Patient     Fs = 100.0 Hz\n",
      "Flow Patient     Fs = 100.0 Hz\n",
      "Effort THO       Fs = 100.0 Hz\n",
      "Effort ABD       Fs = 100.0 Hz\n",
      "SpO2             Fs = 1.0 Hz\n",
      "Body             Fs = 1.0 Hz\n",
      "PulseRate        Fs = 1.0 Hz\n",
      "Mic              Fs = 48000.0 Hz\n",
      "Tracheal         Fs = 48000.0 Hz\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "\n",
    "edf_path = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\\00000995-100507[001].edf\") \n",
    "with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "    labels = f.getSignalLabels()          # list of channel names\n",
    "    fs     = f.getSampleFrequencies()     # numpy array, one per channel\n",
    "\n",
    "for lbl, rate in zip(labels, fs):\n",
    "    print(f\"{lbl:15s}  Fs = {rate:.1f} Hz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549df752",
   "metadata": {},
   "source": [
    "## Read RML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a132679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Parsed 47 nasal events and 221 respiratory events\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snore</td>\n",
       "      <td>3934.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snore</td>\n",
       "      <td>4053.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snore</td>\n",
       "      <td>4107.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Snore</td>\n",
       "      <td>4113.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snore</td>\n",
       "      <td>5342.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type   Start  Duration  Machine\n",
       "0  Snore  3934.5       3.5     True\n",
       "1  Snore  4053.5       9.5     True\n",
       "2  Snore  4107.0       4.5     True\n",
       "3  Snore  4113.5       9.5     True\n",
       "4  Snore  5342.5       4.0     True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Start</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>3752.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>3783.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>3813.5</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hypopnea</td>\n",
       "      <td>3878.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type   Start  Duration\n",
       "0  Hypopnea  3752.5      10.0\n",
       "1  Hypopnea  3783.0      12.0\n",
       "2  Hypopnea  3813.5      10.5\n",
       "3  Hypopnea  3842.0      10.0\n",
       "4  Hypopnea  3878.0      11.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type    Start  Duration  Machine\n",
      "0   Snore   3934.5       3.5     True\n",
      "1   Snore   4053.5       9.5     True\n",
      "2   Snore   4107.0       4.5     True\n",
      "3   Snore   4113.5       9.5     True\n",
      "4   Snore   5342.5       4.0     True\n",
      "5   Snore   5389.5       8.0     True\n",
      "6   Snore   5414.0       7.5     True\n",
      "7   Snore   5437.0       4.0     True\n",
      "8   Snore   5490.0       4.0     True\n",
      "9   Snore   5964.5       4.0     True\n",
      "10  Snore   5998.5       4.5     True\n",
      "11  Snore   6061.0       7.0     True\n",
      "12  Snore   6070.0       3.5     True\n",
      "13  Snore   6082.5       4.5     True\n",
      "14  Snore   6128.0       3.5     True\n",
      "15  Snore   6142.0       7.5     True\n",
      "16  Snore   6200.5       7.5     True\n",
      "17  Snore   6249.0       4.0     True\n",
      "18  Snore   6282.5      12.0     True\n",
      "19  Snore   6314.5       3.5     True\n",
      "20  Snore   6334.5       6.5     True\n",
      "21  Snore   6404.0       3.5     True\n",
      "22  Snore   6419.5      10.0     True\n",
      "23  Snore   6436.0       4.0     True\n",
      "24  Snore   6446.0       4.5     True\n",
      "25  Snore   6456.5       4.5     True\n",
      "26  Snore   6477.5      35.5     True\n",
      "27  Snore   6519.5      32.5     True\n",
      "28  Snore   6558.0      47.5     True\n",
      "29  Snore   6612.0      10.0     True\n",
      "30  Snore   6628.0       4.0     True\n",
      "31  Snore   6638.0       6.5     True\n",
      "32  Snore   6650.5      55.0     True\n",
      "33  Snore   6712.0       7.0     True\n",
      "34  Snore   6725.5      11.0     True\n",
      "35  Snore   6742.5      32.0     True\n",
      "36  Snore   6776.5      27.5     True\n",
      "37  Snore   6810.0       4.0     True\n",
      "38  Snore   6828.0       8.0     True\n",
      "39  Snore   6842.5       4.0     True\n",
      "40  Snore   6848.5       4.0     True\n",
      "41  Snore   6891.0      17.5     True\n",
      "42  Snore   9513.5       8.0     True\n",
      "43  Snore   9619.5      11.5     True\n",
      "44  Snore   9992.5       4.5     True\n",
      "45  Snore  10353.5       3.5     True\n",
      "46  Snore  13884.5       4.0     True\n",
      "                 Type    Start  Duration\n",
      "0            Hypopnea   3752.5      10.0\n",
      "1            Hypopnea   3783.0      12.0\n",
      "2            Hypopnea   3813.5      10.5\n",
      "3            Hypopnea   3842.0      10.0\n",
      "4            Hypopnea   3878.0      11.0\n",
      "..                ...      ...       ...\n",
      "216  ObstructiveApnea  17610.0      10.0\n",
      "217  ObstructiveApnea  17642.5      16.0\n",
      "218  ObstructiveApnea  17682.0      18.5\n",
      "219          Hypopnea  17820.5      11.5\n",
      "220          Hypopnea  17855.0      12.0\n",
      "\n",
      "[221 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0 . HARD-CODE path to your plain-text file\n",
    "# ----------------------------------------------------------------------\n",
    "TXT_PATH = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\\00000995-100507.txt\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1 . Regular expressions\n",
    "# ----------------------------------------------------------------------\n",
    "# Grab the whole <Event ...> tag that sits on one line\n",
    "event_tag   = re.compile(r'<Event\\b[^>]*>')\n",
    "# Pull out every key=\"value\" pair inside that tag\n",
    "attr_kv     = re.compile(r'(\\w+)=\"([^\"]+)\"')\n",
    "\n",
    "nasal_rows, resp_rows = [], []\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2 . Scan the file line-by-line\n",
    "# ----------------------------------------------------------------------\n",
    "with TXT_PATH.open(encoding=\"utf-8\") as fh:\n",
    "    for raw in fh:\n",
    "        m = event_tag.search(raw)\n",
    "        if not m:\n",
    "            continue                      # line has no <Event …> tag\n",
    "\n",
    "        tag_string = m.group(0)\n",
    "        attrs = dict(attr_kv.findall(tag_string))\n",
    "\n",
    "        family = attrs.get(\"Family\")\n",
    "        if family == \"Nasal\":\n",
    "            nasal_rows.append({\n",
    "                \"Type\":     attrs.get(\"Type\"),\n",
    "                \"Start\":    float(attrs[\"Start\"]),\n",
    "                \"Duration\": float(attrs[\"Duration\"]),\n",
    "                \"Machine\":  attrs.get(\"Machine\", \"false\").lower() == \"true\"\n",
    "            })\n",
    "\n",
    "        elif family == \"Respiratory\":\n",
    "            resp_rows.append({\n",
    "                \"Type\":     attrs.get(\"Type\"),\n",
    "                \"Start\":    float(attrs[\"Start\"]),\n",
    "                \"Duration\": float(attrs[\"Duration\"])\n",
    "            })\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3 . Build tidy DataFrames\n",
    "# ----------------------------------------------------------------------\n",
    "nasal_df = pd.DataFrame(nasal_rows, columns=[\"Type\", \"Start\", \"Duration\", \"Machine\"])\n",
    "resp_df  = pd.DataFrame(resp_rows,  columns=[\"Type\", \"Start\", \"Duration\"])\n",
    "\n",
    "print(\"✅  Parsed\", len(nasal_df), \"nasal events and\", len(resp_df), \"respiratory events\")\n",
    "display(nasal_df.head())\n",
    "display(resp_df.head())\n",
    "print(nasal_df)\n",
    "print(resp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f565c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined shape: (857616000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nasal</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nasal   resp\n",
       "0   False  False\n",
       "1   False  False\n",
       "2   False  False\n",
       "3   False  False\n",
       "4   False  False\n",
       "5   False  False\n",
       "6   False  False\n",
       "7   False  False\n",
       "8   False  False\n",
       "9   False  False\n",
       "10  False  False\n",
       "11  False  False\n",
       "12  False  False\n",
       "13  False  False\n",
       "14  False  False\n",
       "15  False  False\n",
       "16  False  False\n",
       "17  False  False\n",
       "18  False  False\n",
       "19  False  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- after you have nasal_df and resp_df from your parsing ---\n",
    "\n",
    "# 1. figure out how many samples we need in total\n",
    "#    time of last event end = max( Start + Duration ) across both\n",
    "t_end_nasal = (nasal_df[\"Start\"] + nasal_df[\"Duration\"]).max()\n",
    "t_end_resp  = (resp_df [\"Start\"] + resp_df [\"Duration\"]).max()\n",
    "t_end       = max(t_end_nasal, t_end_resp)\n",
    "\n",
    "# total samples at 48 000 Hz\n",
    "sr = 48000\n",
    "total_samples = int(np.ceil(t_end * sr))\n",
    "\n",
    "# 2. make two all‐False masks\n",
    "nasal_mask = np.zeros(total_samples, dtype=bool)\n",
    "resp_mask  = np.zeros(total_samples, dtype=bool)\n",
    "\n",
    "# 3. fill in True for each event window\n",
    "for _, row in nasal_df.iterrows():\n",
    "    start_idx = int(row[\"Start\"]    * sr)\n",
    "    end_idx   = start_idx + int(row[\"Duration\"] * sr)\n",
    "    nasal_mask[start_idx:end_idx] = True\n",
    "\n",
    "for _, row in resp_df.iterrows():\n",
    "    start_idx = int(row[\"Start\"]    * sr)\n",
    "    end_idx   = start_idx + int(row[\"Duration\"] * sr)\n",
    "    resp_mask[start_idx:end_idx] = True\n",
    "\n",
    "# 4. combine into a single array or DataFrame\n",
    "#    e.g. (n_samples x 2) array, column 0=nasal, 1=resp\n",
    "combined = np.vstack([nasal_mask, resp_mask]).T\n",
    "\n",
    "# or as a pandas DataFrame, which might be handy for slicing\n",
    "combined_df = pd.DataFrame({\n",
    "    \"nasal\": nasal_mask,\n",
    "    \"resp\" : resp_mask\n",
    "})\n",
    "\n",
    "print(\"combined shape:\", combined.shape)\n",
    "display(combined_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be72e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined shape: (858768000, 2)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "\n",
    "root_folder = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\")\n",
    "patient_id = \"00000995-100507\"\n",
    "\n",
    "tracheal_list = []\n",
    "mic_list      = []\n",
    "\n",
    "for idx in range(1, 6):\n",
    "    edf_path = root_folder / f\"{patient_id}[{idx:03d}].edf\"\n",
    "    if not edf_path.exists():\n",
    "        print(f\"⚠️ missing {edf_path.name}\")\n",
    "        continue\n",
    "\n",
    "    with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "        labels   = f.getSignalLabels()\n",
    "        # find the indices\n",
    "        ti = labels.index(\"Tracheal\")\n",
    "        mi = labels.index(\"Mic\")\n",
    "        # read each channel\n",
    "        tracheal_list.append(f.readSignal(ti))\n",
    "        mic_list.append(f.readSignal(mi))\n",
    "\n",
    "all_tracheal = np.concatenate(tracheal_list)\n",
    "all_mic      = np.concatenate(mic_list)\n",
    "\n",
    "combined = np.vstack((all_tracheal, all_mic)).T\n",
    "\n",
    "print(\"combined shape:\", combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f067ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(858768000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tracheal</th>\n",
       "      <th>Mic</th>\n",
       "      <th>nasal</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.032547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.032822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tracheal       Mic  nasal  resp\n",
       "0  0.002731  0.032547    0.0   0.0\n",
       "1  0.003433  0.032822    0.0   0.0\n",
       "2  0.002945  0.033341    0.0   0.0\n",
       "3  0.003098  0.033799    0.0   0.0\n",
       "4  0.002274  0.034043    0.0   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_sig  = combined.shape[0]\n",
    "n_mask = combined_df.shape[0]\n",
    "\n",
    "if n_mask < n_sig:\n",
    "    # numpy way:\n",
    "    nasal_full = np.pad(\n",
    "        combined_df[\"nasal\"].values,\n",
    "        (0, n_sig - n_mask),\n",
    "        mode=\"constant\",\n",
    "        constant_values=False\n",
    "    )\n",
    "    resp_full  = np.pad(\n",
    "        combined_df[\"resp\"].values,\n",
    "        (0, n_sig - n_mask),\n",
    "        mode=\"constant\",\n",
    "        constant_values=False\n",
    "    )\n",
    "elif n_mask > n_sig:\n",
    "    pad_len  = n_mask - n_sig\n",
    "    combined = np.vstack([\n",
    "        combined,\n",
    "        np.zeros((pad_len, combined.shape[1]), dtype=combined.dtype)\n",
    "    ])\n",
    "    n_sig = combined.shape[0]  # now equal\n",
    "    nasal_full = combined_df[\"nasal\"].values\n",
    "    resp_full  = combined_df[\"resp\"].values\n",
    "\n",
    "else:\n",
    "    # already same length\n",
    "    nasal_full = combined_df[\"nasal\"].values\n",
    "    resp_full  = combined_df[\"resp\"].values\n",
    "\n",
    "# --- 3) Build your final DataFrame ---\n",
    "signal_df = pd.DataFrame(\n",
    "    np.hstack([\n",
    "        combined,                         # (n_sig×2) floats\n",
    "        nasal_full[:, None].astype(int),  # cast to 0/1 if you like\n",
    "        resp_full[:, None].astype(int)\n",
    "    ]),\n",
    "    columns=[\"Tracheal\", \"Mic\", \"nasal\", \"resp\"]\n",
    ")\n",
    "\n",
    "print(signal_df.shape)   \n",
    "display(signal_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fcd8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_mask_events(signal_df, mask_cols=(\"nasal\", \"resp\"), sr=48000):\n",
    "    \"\"\"\n",
    "    For each column in mask_cols, find the contiguous runs of 1's in signal_df[col].\n",
    "    Returns a dict mapping col → list of intervals, where each interval is a dict:\n",
    "      {\n",
    "        \"start_idx\": int,    # sample index where mask turns on\n",
    "        \"end_idx\":   int,    # sample index where mask turns off\n",
    "        \"start_time\": float, # seconds\n",
    "        \"end_time\":   float  # seconds\n",
    "      }\n",
    "    \"\"\"\n",
    "    events = {}\n",
    "    for col in mask_cols:\n",
    "        mask = signal_df[col].astype(bool).values\n",
    "        # diffs: +1 where 0→1,  -1 where 1→0\n",
    "        diff = np.diff(mask.astype(int))\n",
    "        starts = np.where(diff ==  1)[0] + 1\n",
    "        ends   = np.where(diff == -1)[0] + 1\n",
    "\n",
    "        # handle case where mask is already True at index 0\n",
    "        if mask[0]:\n",
    "            starts = np.insert(starts, 0, 0)\n",
    "        # handle case where mask stays True until the end\n",
    "        if mask[-1]:\n",
    "            ends = np.append(ends, len(mask))\n",
    "\n",
    "        intervals = []\n",
    "        for s, e in zip(starts, ends):\n",
    "            intervals.append({\n",
    "                \"start_idx\":  int(s),\n",
    "                \"end_idx\":    int(e),\n",
    "                \"start_time\": s / sr,\n",
    "                \"end_time\":   e / sr\n",
    "            })\n",
    "        events[col] = intervals\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268844df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nasal events (47 runs):\n",
      "  188856000–189024000  (3934.500s → 3938.000s)\n",
      "  194568000–195024000  (4053.500s → 4063.000s)\n",
      "  197136000–197352000  (4107.000s → 4111.500s)\n",
      "  197448000–197904000  (4113.500s → 4123.000s)\n",
      "  256440000–256632000  (5342.500s → 5346.500s)\n",
      "  258696000–259080000  (5389.500s → 5397.500s)\n",
      "  259872000–260232000  (5414.000s → 5421.500s)\n",
      "  260976000–261168000  (5437.000s → 5441.000s)\n",
      "  263520000–263712000  (5490.000s → 5494.000s)\n",
      "  286296000–286488000  (5964.500s → 5968.500s)\n",
      "  287928000–288144000  (5998.500s → 6003.000s)\n",
      "  290928000–291264000  (6061.000s → 6068.000s)\n",
      "  291360000–291528000  (6070.000s → 6073.500s)\n",
      "  291960000–292176000  (6082.500s → 6087.000s)\n",
      "  294144000–294312000  (6128.000s → 6131.500s)\n",
      "  294816000–295176000  (6142.000s → 6149.500s)\n",
      "  297624000–297984000  (6200.500s → 6208.000s)\n",
      "  299952000–300144000  (6249.000s → 6253.000s)\n",
      "  301560000–302136000  (6282.500s → 6294.500s)\n",
      "  303096000–303264000  (6314.500s → 6318.000s)\n",
      "  304056000–304368000  (6334.500s → 6341.000s)\n",
      "  307392000–307560000  (6404.000s → 6407.500s)\n",
      "  308136000–308616000  (6419.500s → 6429.500s)\n",
      "  308928000–309120000  (6436.000s → 6440.000s)\n",
      "  309408000–309624000  (6446.000s → 6450.500s)\n",
      "  309912000–310128000  (6456.500s → 6461.000s)\n",
      "  310920000–312624000  (6477.500s → 6513.000s)\n",
      "  312936000–314496000  (6519.500s → 6552.000s)\n",
      "  314784000–317064000  (6558.000s → 6605.500s)\n",
      "  317376000–317856000  (6612.000s → 6622.000s)\n",
      "  318144000–318336000  (6628.000s → 6632.000s)\n",
      "  318624000–318936000  (6638.000s → 6644.500s)\n",
      "  319224000–321864000  (6650.500s → 6705.500s)\n",
      "  322176000–322512000  (6712.000s → 6719.000s)\n",
      "  322824000–323352000  (6725.500s → 6736.500s)\n",
      "  323640000–325176000  (6742.500s → 6774.500s)\n",
      "  325272000–326592000  (6776.500s → 6804.000s)\n",
      "  326880000–327072000  (6810.000s → 6814.000s)\n",
      "  327744000–328128000  (6828.000s → 6836.000s)\n",
      "  328440000–328632000  (6842.500s → 6846.500s)\n",
      "  328728000–328920000  (6848.500s → 6852.500s)\n",
      "  330768000–331608000  (6891.000s → 6908.500s)\n",
      "  456648000–457032000  (9513.500s → 9521.500s)\n",
      "  461736000–462288000  (9619.500s → 9631.000s)\n",
      "  479640000–479856000  (9992.500s → 9997.000s)\n",
      "  496968000–497136000  (10353.500s → 10357.000s)\n",
      "  666456000–666648000  (13884.500s → 13888.500s)\n",
      "\n",
      "resp events (221 runs):\n",
      "  180120000–180600000  (3752.500s → 3762.500s)\n",
      "  181584000–182160000  (3783.000s → 3795.000s)\n",
      "  183048000–183552000  (3813.500s → 3824.000s)\n",
      "  184416000–184896000  (3842.000s → 3852.000s)\n",
      "  186144000–186672000  (3878.000s → 3889.000s)\n",
      "  187608000–188208000  (3908.500s → 3921.000s)\n",
      "  192816000–193344000  (4017.000s → 4028.000s)\n",
      "  203616000–204096000  (4242.000s → 4252.000s)\n",
      "  204624000–205104000  (4263.000s → 4273.000s)\n",
      "  211464000–211992000  (4405.500s → 4416.500s)\n",
      "  214056000–214584000  (4459.500s → 4470.500s)\n",
      "  215184000–215688000  (4483.000s → 4493.500s)\n",
      "  216144000–216672000  (4503.000s → 4514.000s)\n",
      "  217944000–218496000  (4540.500s → 4552.000s)\n",
      "  219552000–220080000  (4574.000s → 4585.000s)\n",
      "  220800000–221280000  (4600.000s → 4610.000s)\n",
      "  221928000–222456000  (4623.500s → 4634.500s)\n",
      "  223464000–223968000  (4655.500s → 4666.000s)\n",
      "  225504000–225984000  (4698.000s → 4708.000s)\n",
      "  228768000–229344000  (4766.000s → 4778.000s)\n",
      "  233736000–234264000  (4869.500s → 4880.500s)\n",
      "  234984000–235560000  (4895.500s → 4907.500s)\n",
      "  242208000–242712000  (5046.000s → 5056.500s)\n",
      "  244584000–245112000  (5095.500s → 5106.500s)\n",
      "  245760000–246264000  (5120.000s → 5130.500s)\n",
      "  259176000–259680000  (5399.500s → 5410.000s)\n",
      "  260280000–260808000  (5422.500s → 5433.500s)\n",
      "  261240000–261768000  (5442.500s → 5453.500s)\n",
      "  267216000–267696000  (5567.000s → 5577.000s)\n",
      "  268272000–268800000  (5589.000s → 5600.000s)\n",
      "  269280000–269784000  (5610.000s → 5620.500s)\n",
      "  270456000–271056000  (5634.500s → 5647.000s)\n",
      "  271680000–272160000  (5660.000s → 5670.000s)\n",
      "  275496000–275976000  (5739.500s → 5749.500s)\n",
      "  276456000–276936000  (5759.500s → 5769.500s)\n",
      "  291072000–291576000  (6064.000s → 6074.500s)\n",
      "  295248000–295752000  (6151.000s → 6161.500s)\n",
      "  300552000–301104000  (6261.500s → 6273.000s)\n",
      "  304080000–304632000  (6335.000s → 6346.500s)\n",
      "  305400000–305928000  (6362.500s → 6373.500s)\n",
      "  319992000–320472000  (6666.500s → 6676.500s)\n",
      "  326016000–326592000  (6792.000s → 6804.000s)\n",
      "  326976000–327552000  (6812.000s → 6824.000s)\n",
      "  328848000–329424000  (6851.000s → 6863.000s)\n",
      "  330168000–330696000  (6878.500s → 6889.500s)\n",
      "  337344000–337968000  (7028.000s → 7041.000s)\n",
      "  355992000–356520000  (7416.500s → 7427.500s)\n",
      "  360888000–361440000  (7518.500s → 7530.000s)\n",
      "  364440000–364968000  (7592.500s → 7603.500s)\n",
      "  366024000–366504000  (7625.500s → 7635.500s)\n",
      "  366960000–367536000  (7645.000s → 7657.000s)\n",
      "  368328000–368952000  (7673.500s → 7686.500s)\n",
      "  378384000–378936000  (7883.000s → 7894.500s)\n",
      "  388440000–388944000  (8092.500s → 8103.000s)\n",
      "  390240000–390816000  (8130.000s → 8142.000s)\n",
      "  392784000–393288000  (8183.000s → 8193.500s)\n",
      "  394416000–394896000  (8217.000s → 8227.000s)\n",
      "  401232000–401856000  (8359.000s → 8372.000s)\n",
      "  402912000–403512000  (8394.000s → 8406.500s)\n",
      "  406176000–406656000  (8462.000s → 8472.000s)\n",
      "  408576000–409056000  (8512.000s → 8522.000s)\n",
      "  411672000–412152000  (8576.500s → 8586.500s)\n",
      "  417384000–417960000  (8695.500s → 8707.500s)\n",
      "  418704000–419232000  (8723.000s → 8734.000s)\n",
      "  420120000–420648000  (8752.500s → 8763.500s)\n",
      "  421320000–421872000  (8777.500s → 8789.000s)\n",
      "  422784000–423384000  (8808.000s → 8820.500s)\n",
      "  423840000–424368000  (8830.000s → 8841.000s)\n",
      "  430296000–430848000  (8964.500s → 8976.000s)\n",
      "  432168000–432816000  (9003.500s → 9017.000s)\n",
      "  433968000–434616000  (9041.000s → 9054.500s)\n",
      "  437016000–437880000  (9104.500s → 9122.500s)\n",
      "  464136000–464616000  (9669.500s → 9679.500s)\n",
      "  465216000–465744000  (9692.000s → 9703.000s)\n",
      "  467016000–467520000  (9729.500s → 9740.000s)\n",
      "  469272000–469776000  (9776.500s → 9787.000s)\n",
      "  480600000–481080000  (10012.500s → 10022.500s)\n",
      "  481584000–482064000  (10033.000s → 10043.000s)\n",
      "  512880000–513480000  (10685.000s → 10697.500s)\n",
      "  516624000–517176000  (10763.000s → 10774.500s)\n",
      "  518904000–519384000  (10810.500s → 10820.500s)\n",
      "  523656000–524136000  (10909.500s → 10919.500s)\n",
      "  532032000–532608000  (11084.000s → 11096.000s)\n",
      "  536400000–537000000  (11175.000s → 11187.500s)\n",
      "  542904000–543432000  (11310.500s → 11321.500s)\n",
      "  545328000–545856000  (11361.000s → 11372.000s)\n",
      "  547248000–547728000  (11401.000s → 11411.000s)\n",
      "  549960000–550464000  (11457.500s → 11468.000s)\n",
      "  561864000–562416000  (11705.500s → 11717.000s)\n",
      "  563424000–563952000  (11738.000s → 11749.000s)\n",
      "  566616000–567120000  (11804.500s → 11815.000s)\n",
      "  567792000–568272000  (11829.000s → 11839.000s)\n",
      "  569160000–569688000  (11857.500s → 11868.500s)\n",
      "  570936000–571416000  (11894.500s → 11904.500s)\n",
      "  571800000–572472000  (11912.500s → 11926.500s)\n",
      "  573744000–574272000  (11953.000s → 11964.000s)\n",
      "  576528000–577080000  (12011.000s → 12022.500s)\n",
      "  579336000–579864000  (12069.500s → 12080.500s)\n",
      "  584136000–584664000  (12169.500s → 12180.500s)\n",
      "  586320000–586800000  (12215.000s → 12225.000s)\n",
      "  587688000–588216000  (12243.500s → 12254.500s)\n",
      "  589008000–589536000  (12271.000s → 12282.000s)\n",
      "  590568000–591096000  (12303.500s → 12314.500s)\n",
      "  592920000–593472000  (12352.500s → 12364.000s)\n",
      "  594768000–595320000  (12391.000s → 12402.500s)\n",
      "  597048000–597648000  (12438.500s → 12451.000s)\n",
      "  599112000–599832000  (12481.500s → 12496.500s)\n",
      "  600984000–601512000  (12520.500s → 12531.500s)\n",
      "  602904000–603408000  (12560.500s → 12571.000s)\n",
      "  617928000–618432000  (12873.500s → 12884.000s)\n",
      "  624888000–625416000  (13018.500s → 13029.500s)\n",
      "  625992000–626496000  (13041.500s → 13052.000s)\n",
      "  627144000–627744000  (13065.500s → 13078.000s)\n",
      "  635160000–635760000  (13232.500s → 13245.000s)\n",
      "  636936000–637584000  (13269.500s → 13283.000s)\n",
      "  640056000–640560000  (13334.500s → 13345.000s)\n",
      "  651000000–651504000  (13562.500s → 13573.000s)\n",
      "  652080000–652560000  (13585.000s → 13595.000s)\n",
      "  667440000–667944000  (13905.000s → 13915.500s)\n",
      "  670344000–670848000  (13965.500s → 13976.000s)\n",
      "  671544000–672072000  (13990.500s → 14001.500s)\n",
      "  674808000–675336000  (14058.500s → 14069.500s)\n",
      "  675912000–676464000  (14081.500s → 14093.000s)\n",
      "  677064000–677592000  (14105.500s → 14116.500s)\n",
      "  678264000–678768000  (14130.500s → 14141.000s)\n",
      "  679392000–679944000  (14154.000s → 14165.500s)\n",
      "  680712000–681240000  (14181.500s → 14192.500s)\n",
      "  682008000–682536000  (14208.500s → 14219.500s)\n",
      "  683304000–683832000  (14235.500s → 14246.500s)\n",
      "  684576000–685128000  (14262.000s → 14273.500s)\n",
      "  685728000–686208000  (14286.000s → 14296.000s)\n",
      "  686928000–687408000  (14311.000s → 14321.000s)\n",
      "  687936000–688464000  (14332.000s → 14343.000s)\n",
      "  689088000–689568000  (14356.000s → 14366.000s)\n",
      "  692016000–692544000  (14417.000s → 14428.000s)\n",
      "  693288000–693792000  (14443.500s → 14454.000s)\n",
      "  703560000–704040000  (14657.500s → 14667.500s)\n",
      "  706440000–706944000  (14717.500s → 14728.000s)\n",
      "  707472000–707976000  (14739.000s → 14749.500s)\n",
      "  711960000–712512000  (14832.500s → 14844.000s)\n",
      "  712992000–713496000  (14854.000s → 14864.500s)\n",
      "  714312000–714864000  (14881.500s → 14893.000s)\n",
      "  715824000–716400000  (14913.000s → 14925.000s)\n",
      "  716952000–717552000  (14936.500s → 14949.000s)\n",
      "  718176000–718704000  (14962.000s → 14973.000s)\n",
      "  719832000–720408000  (14996.500s → 15008.500s)\n",
      "  721368000–721896000  (15028.500s → 15039.500s)\n",
      "  722544000–723024000  (15053.000s → 15063.000s)\n",
      "  723528000–724104000  (15073.500s → 15085.500s)\n",
      "  724728000–725280000  (15098.500s → 15110.000s)\n",
      "  726144000–726696000  (15128.000s → 15139.500s)\n",
      "  727296000–728016000  (15152.000s → 15167.000s)\n",
      "  728736000–729288000  (15182.000s → 15193.500s)\n",
      "  730032000–730656000  (15209.000s → 15222.000s)\n",
      "  731352000–731952000  (15236.500s → 15249.000s)\n",
      "  732624000–733176000  (15263.000s → 15274.500s)\n",
      "  733872000–734400000  (15289.000s → 15300.000s)\n",
      "  734952000–735504000  (15311.500s → 15323.000s)\n",
      "  736344000–736920000  (15340.500s → 15352.500s)\n",
      "  737760000–738312000  (15370.000s → 15381.500s)\n",
      "  739008000–739560000  (15396.000s → 15407.500s)\n",
      "  740208000–740736000  (15421.000s → 15432.000s)\n",
      "  741408000–742008000  (15446.000s → 15458.500s)\n",
      "  742680000–743304000  (15472.500s → 15485.500s)\n",
      "  743784000–744504000  (15495.500s → 15510.500s)\n",
      "  745104000–745584000  (15523.000s → 15533.000s)\n",
      "  755280000–755880000  (15735.000s → 15747.500s)\n",
      "  756936000–757416000  (15769.500s → 15779.500s)\n",
      "  758688000–759360000  (15806.000s → 15820.000s)\n",
      "  760176000–760800000  (15837.000s → 15850.000s)\n",
      "  762120000–762744000  (15877.500s → 15890.500s)\n",
      "  764568000–765096000  (15928.500s → 15939.500s)\n",
      "  765840000–766440000  (15955.000s → 15967.500s)\n",
      "  769248000–769824000  (16026.000s → 16038.000s)\n",
      "  771024000–771648000  (16063.000s → 16076.000s)\n",
      "  772224000–772800000  (16088.000s → 16100.000s)\n",
      "  773256000–773784000  (16109.500s → 16120.500s)\n",
      "  774792000–775296000  (16141.500s → 16152.000s)\n",
      "  784224000–784728000  (16338.000s → 16348.500s)\n",
      "  785400000–785952000  (16362.500s → 16374.000s)\n",
      "  786768000–787296000  (16391.000s → 16402.000s)\n",
      "  787776000–788496000  (16412.000s → 16427.000s)\n",
      "  789312000–790032000  (16444.000s → 16459.000s)\n",
      "  790632000–791208000  (16471.500s → 16483.500s)\n",
      "  792120000–792720000  (16502.500s → 16515.000s)\n",
      "  793512000–794040000  (16531.500s → 16542.500s)\n",
      "  794832000–795384000  (16559.000s → 16570.500s)\n",
      "  796032000–796512000  (16584.000s → 16594.000s)\n",
      "  797232000–797808000  (16609.000s → 16621.000s)\n",
      "  798552000–799152000  (16636.500s → 16649.000s)\n",
      "  800016000–800544000  (16667.000s → 16678.000s)\n",
      "  801288000–801888000  (16693.500s → 16706.000s)\n",
      "  802608000–803160000  (16721.000s → 16732.500s)\n",
      "  804072000–804600000  (16751.500s → 16762.500s)\n",
      "  806376000–806952000  (16799.500s → 16811.500s)\n",
      "  807528000–808080000  (16823.500s → 16835.000s)\n",
      "  808728000–809568000  (16848.500s → 16866.000s)\n",
      "  810480000–811008000  (16885.000s → 16896.000s)\n",
      "  813072000–813696000  (16939.000s → 16952.000s)\n",
      "  814680000–815280000  (16972.500s → 16985.000s)\n",
      "  819264000–819840000  (17068.000s → 17080.000s)\n",
      "  820776000–821328000  (17099.500s → 17111.000s)\n",
      "  822000000–822504000  (17125.000s → 17135.500s)\n",
      "  823224000–823800000  (17150.500s → 17162.500s)\n",
      "  824400000–825048000  (17175.000s → 17188.500s)\n",
      "  825528000–826296000  (17198.500s → 17214.500s)\n",
      "  827232000–827760000  (17234.000s → 17245.000s)\n",
      "  828816000–829344000  (17267.000s → 17278.000s)\n",
      "  830952000–831552000  (17311.500s → 17324.000s)\n",
      "  833160000–833688000  (17357.500s → 17368.500s)\n",
      "  834192000–834744000  (17379.000s → 17390.500s)\n",
      "  835416000–836232000  (17404.500s → 17421.500s)\n",
      "  837336000–838152000  (17444.500s → 17461.500s)\n",
      "  839784000–840504000  (17495.500s → 17510.500s)\n",
      "  841896000–842904000  (17539.500s → 17560.500s)\n",
      "  844128000–844680000  (17586.000s → 17597.500s)\n",
      "  845280000–845760000  (17610.000s → 17620.000s)\n",
      "  846840000–847608000  (17642.500s → 17658.500s)\n",
      "  848736000–849624000  (17682.000s → 17700.500s)\n",
      "  855384000–855936000  (17820.500s → 17832.000s)\n",
      "  857040000–857616000  (17855.000s → 17867.000s)\n"
     ]
    }
   ],
   "source": [
    "events = extract_mask_events(signal_df)\n",
    "\n",
    "# To print them:\n",
    "for col, ivals in events.items():\n",
    "    print(f\"\\n{col} events ({len(ivals)} runs):\")\n",
    "    for iv in ivals:\n",
    "        print(f\"  {iv['start_idx']}–{iv['end_idx']}  ({iv['start_time']:.3f}s → {iv['end_time']:.3f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7dadc",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39751a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final signal_df shape: (858768000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tracheal</th>\n",
       "      <th>Mic</th>\n",
       "      <th>nasal</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.032547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.032822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tracheal       Mic  nasal  resp\n",
       "0  0.002731  0.032547    0.0   0.0\n",
       "1  0.003433  0.032822    0.0   0.0\n",
       "2  0.002945  0.033341    0.0   0.0\n",
       "3  0.003098  0.033799    0.0   0.0\n",
       "4  0.002274  0.034043    0.0   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "\n",
    "\n",
    "def parse_event_xml(txt_path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parse <Event …> tags from a plain‐text file into two DataFrames:\n",
    "      - nasal_df: columns [Type, Start, Duration, Machine]\n",
    "      - resp_df:  columns [Type, Start, Duration]\n",
    "    \"\"\"\n",
    "    event_tag = re.compile(r'<Event\\b[^>]*>')\n",
    "    attr_kv   = re.compile(r'(\\w+)=\"([^\"]+)\"')\n",
    "\n",
    "    nasal_rows, resp_rows = [], []\n",
    "    with txt_path.open(encoding=\"utf-8\") as fh:\n",
    "        for line in fh:\n",
    "            m = event_tag.search(line)\n",
    "            if not m:\n",
    "                continue\n",
    "\n",
    "            attrs = dict(attr_kv.findall(m.group(0)))\n",
    "            fam   = attrs.get(\"Family\")\n",
    "            if fam == \"Nasal\":\n",
    "                nasal_rows.append({\n",
    "                    \"Type\":     attrs.get(\"Type\"),\n",
    "                    \"Start\":    float(attrs[\"Start\"]),\n",
    "                    \"Duration\": float(attrs[\"Duration\"]),\n",
    "                    \"Machine\":  attrs.get(\"Machine\", \"false\").lower() == \"true\"\n",
    "                })\n",
    "            elif fam == \"Respiratory\":\n",
    "                resp_rows.append({\n",
    "                    \"Type\":     attrs.get(\"Type\"),\n",
    "                    \"Start\":    float(attrs[\"Start\"]),\n",
    "                    \"Duration\": float(attrs[\"Duration\"])\n",
    "                })\n",
    "\n",
    "    nasal_df = pd.DataFrame(nasal_rows, columns=[\"Type\",\"Start\",\"Duration\",\"Machine\"])\n",
    "    resp_df  = pd.DataFrame(resp_rows,  columns=[\"Type\",\"Start\",\"Duration\"])\n",
    "    return nasal_df, resp_df\n",
    "\n",
    "\n",
    "def build_event_mask(nasal_df: pd.DataFrame,\n",
    "                     resp_df: pd.DataFrame,\n",
    "                     sample_rate: int = 48_000\n",
    "                    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given nasal_df & resp_df with Start/Duration in seconds,\n",
    "    return a DataFrame of shape (n_samples, 2) with boolean masks.\n",
    "    \"\"\"\n",
    "    # find final time\n",
    "    t_end = max(\n",
    "        (nasal_df[\"Start\"] + nasal_df[\"Duration\"]).max(),\n",
    "        ( resp_df[\"Start\"] +  resp_df[\"Duration\"]).max()\n",
    "    )\n",
    "    n_samples = int(np.ceil(t_end * sample_rate))\n",
    "    nasal_mask = np.zeros(n_samples, dtype=bool)\n",
    "    resp_mask  = np.zeros(n_samples, dtype=bool)\n",
    "\n",
    "    for df, mask in ((nasal_df, nasal_mask), (resp_df, resp_mask)):\n",
    "        for _, row in df.iterrows():\n",
    "            start = int(row[\"Start\"]    * sample_rate)\n",
    "            length= int(row[\"Duration\"] * sample_rate)\n",
    "            mask[start : start+length] = True\n",
    "\n",
    "    return pd.DataFrame({\"nasal\": nasal_mask, \"resp\": resp_mask})\n",
    "\n",
    "\n",
    "def load_and_concatenate_signals(root: Path,\n",
    "                                 patient_id: str,\n",
    "                                 n_segments: int = 5\n",
    "                                ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load 'Tracheal' and 'Mic' from each EDF segment and concatenate.\n",
    "    Returns an (n_samples, 2) float array.\n",
    "    \"\"\"\n",
    "    tracheal_list, mic_list = [], []\n",
    "    for i in range(1, n_segments+1):\n",
    "        edf_path = root / f\"{patient_id}[{i:03d}].edf\"\n",
    "        if not edf_path.exists():\n",
    "            print(f\"⚠️ Missing {edf_path.name}\")\n",
    "            continue\n",
    "\n",
    "        with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "            labels = f.getSignalLabels()\n",
    "            ti = labels.index(\"Tracheal\")\n",
    "            mi = labels.index(\"Mic\")\n",
    "            tracheal_list.append(f.readSignal(ti))\n",
    "            mic_list.append(f.readSignal(mi))\n",
    "\n",
    "    all_trach = np.concatenate(tracheal_list)\n",
    "    all_mic   = np.concatenate(mic_list)\n",
    "    return np.vstack([all_trach, all_mic]).T\n",
    "\n",
    "\n",
    "def align_and_build_dataframe(signals: np.ndarray,\n",
    "                              masks: pd.DataFrame\n",
    "                             ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Pads/truncates signals and masks to the same length, then\n",
    "    returns a DataFrame with columns ['Tracheal','Mic','nasal','resp'].\n",
    "    \"\"\"\n",
    "    n_sig  = signals.shape[0]\n",
    "    n_mask = len(masks)\n",
    "\n",
    "    # pad the shorter one\n",
    "    if n_sig > n_mask:\n",
    "        pad = np.zeros((n_sig-n_mask, masks.shape[1]), dtype=bool)\n",
    "        masks = pd.concat([masks, pd.DataFrame(pad, columns=masks.columns)], ignore_index=True)\n",
    "    elif n_mask > n_sig:\n",
    "        pad = np.zeros((n_mask-n_sig, signals.shape[1]), dtype=signals.dtype)\n",
    "        signals = np.vstack([signals, pad])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        np.hstack([signals, masks.values.astype(int)]),\n",
    "        columns=[\"Tracheal\",\"Mic\",\"nasal\",\"resp\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Paths & parameters\n",
    "    TXT_PATH    = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\\00000995-100507.txt\")\n",
    "    ROOT_FOLDER = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\")\n",
    "    PATIENT_ID  = \"00000995-100507\"\n",
    "    SR          = 48000\n",
    "\n",
    "    # 1. Parse event XML → DataFrames\n",
    "    nasal_df, resp_df = parse_event_xml(TXT_PATH)\n",
    "\n",
    "    # 2. Build boolean masks at SR\n",
    "    mask_df = build_event_mask(nasal_df, resp_df, sample_rate=SR)\n",
    "\n",
    "    # 3. Load & concatenate EDF signals\n",
    "    signals = load_and_concatenate_signals(ROOT_FOLDER, PATIENT_ID)\n",
    "\n",
    "    # 4. Align & merge into final DataFrame\n",
    "    signal_df = align_and_build_dataframe(signals, mask_df)\n",
    "\n",
    "    print(\"Final signal_df shape:\", signal_df.shape)\n",
    "    display(signal_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131339de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting DataFrame shape: (172800000, 4)\n",
      "   Tracheal       Mic  nasal  resp\n",
      "0 -0.002457  0.012863    0.0   0.0\n",
      "1 -0.003983  0.012863    0.0   0.0\n",
      "2 -0.002548  0.012741    0.0   0.0\n",
      "3 -0.002487  0.012253    0.0   0.0\n",
      "4 -0.002487  0.011337    0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# from pathlib import Path\n",
    "# from typing import Tuple\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import pyedflib\n",
    "\n",
    "\n",
    "# def parse_event_xml(txt_path: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "#     \"\"\"\n",
    "#     Parse <Event …> tags from a plain‐text file into two DataFrames:\n",
    "#       - nasal_df: columns [Type, Start, Duration, Machine]\n",
    "#       - resp_df:  columns [Type, Start, Duration]\n",
    "#     \"\"\"\n",
    "#     event_tag = re.compile(r'<Event\\b[^>]*>')\n",
    "#     attr_kv   = re.compile(r'(\\w+)=\"([^\"]+)\"')\n",
    "\n",
    "#     nasal_rows, resp_rows = [], []\n",
    "#     with txt_path.open(encoding=\"utf-8\") as fh:\n",
    "#         for line in fh:\n",
    "#             m = event_tag.search(line)\n",
    "#             if not m:\n",
    "#                 continue\n",
    "\n",
    "#             attrs = dict(attr_kv.findall(m.group(0)))\n",
    "#             fam   = attrs.get(\"Family\", \"\")\n",
    "#             if fam == \"Nasal\":\n",
    "#                 nasal_rows.append({\n",
    "#                     \"Type\":     attrs.get(\"Type\", \"\"),\n",
    "#                     \"Start\":    float(attrs.get(\"Start\", 0.0)),\n",
    "#                     \"Duration\": float(attrs.get(\"Duration\", 0.0)),\n",
    "#                     \"Machine\":  attrs.get(\"Machine\", \"false\").lower() == \"true\"\n",
    "#                 })\n",
    "#             elif fam == \"Respiratory\":\n",
    "#                 resp_rows.append({\n",
    "#                     \"Type\":     attrs.get(\"Type\", \"\"),\n",
    "#                     \"Start\":    float(attrs.get(\"Start\", 0.0)),\n",
    "#                     \"Duration\": float(attrs.get(\"Duration\", 0.0))\n",
    "#                 })\n",
    "\n",
    "#     nasal_df = pd.DataFrame(nasal_rows, columns=[\"Type\", \"Start\", \"Duration\", \"Machine\"])\n",
    "#     resp_df  = pd.DataFrame(resp_rows,  columns=[\"Type\", \"Start\", \"Duration\"])\n",
    "#     return nasal_df, resp_df\n",
    "\n",
    "\n",
    "# def load_signal(edf_path: Path) -> Tuple[np.ndarray, int]:\n",
    "#     \"\"\"\n",
    "#     Load a single EDF file, returning\n",
    "#       - signals: (n_samples, 2) array [Tracheal, Mic]\n",
    "#       - sample_rate: int\n",
    "#     \"\"\"\n",
    "#     if not edf_path.exists():\n",
    "#         raise FileNotFoundError(f\"Missing file: {edf_path}\")\n",
    "\n",
    "#     with pyedflib.EdfReader(str(edf_path)) as f:\n",
    "#         labels  = f.getSignalLabels()\n",
    "#         ti      = labels.index(\"Tracheal\")\n",
    "#         mi      = labels.index(\"Mic\")\n",
    "#         sr_tr   = f.getSampleFrequency(ti)\n",
    "#         sr_mi   = f.getSampleFrequency(mi)\n",
    "#         if sr_tr != sr_mi:\n",
    "#             raise ValueError(f\"Sampling rates differ: Tracheal={sr_tr}, Mic={sr_mi}\")\n",
    "#         sr       = int(sr_tr)\n",
    "#         tr_sig   = f.readSignal(ti)\n",
    "#         mic_sig  = f.readSignal(mi)\n",
    "\n",
    "#     signals = np.vstack([tr_sig, mic_sig]).T  # shape (n_samples, 2)\n",
    "#     return signals, sr\n",
    "\n",
    "\n",
    "# def build_event_mask(nasal_df: pd.DataFrame,\n",
    "#                      resp_df: pd.DataFrame,\n",
    "#                      sample_rate: int,\n",
    "#                      n_samples: int\n",
    "#                     ) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Build boolean masks for exactly n_samples.\n",
    "#     Discard any event starting beyond n_samples; trim events that spill over.\n",
    "#     \"\"\"\n",
    "#     nasal_mask = np.zeros(n_samples, dtype=bool)\n",
    "#     resp_mask  = np.zeros(n_samples, dtype=bool)\n",
    "\n",
    "#     for df, mask in ((nasal_df, nasal_mask), (resp_df, resp_mask)):\n",
    "#         for _, row in df.iterrows():\n",
    "#             start = int(row[\"Start\"] * sample_rate)\n",
    "#             length = int(row[\"Duration\"] * sample_rate)\n",
    "#             end = start + length\n",
    "\n",
    "#             # discard events that start outside recording\n",
    "#             if start >= n_samples:\n",
    "#                 continue\n",
    "#             # trim any event that spills past the end\n",
    "#             if end > n_samples:\n",
    "#                 end = n_samples\n",
    "\n",
    "#             mask[start:end] = True\n",
    "\n",
    "#     return pd.DataFrame({\"nasal\": nasal_mask, \"resp\": resp_mask})\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # — User parameters: set these paths appropriately —\n",
    "#     TXT_PATH = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\\00000995-100507.txt\")\n",
    "#     EDF_PATH = Path(r\"C:\\Users\\blend\\Desktop\\CS\\hacktech\\data\\00000995-100507[002].edf\")\n",
    "\n",
    "#     # 1. Parse events\n",
    "#     nasal_df, resp_df = parse_event_xml(TXT_PATH)\n",
    "\n",
    "#     # 2. Load the single EDF → get signals + sample rate\n",
    "#     signals, SR = load_signal(EDF_PATH)\n",
    "#     n_samples = signals.shape[0]\n",
    "\n",
    "#     # 3. Build masks, discarding/trimming out-of-range events\n",
    "#     mask_df = build_event_mask(nasal_df, resp_df, sample_rate=SR, n_samples=n_samples)\n",
    "\n",
    "#     # 4. Merge into a final DataFrame\n",
    "#     signal_df = pd.DataFrame(\n",
    "#         np.hstack([signals, mask_df.values.astype(int)]),\n",
    "#         columns=[\"Tracheal\", \"Mic\", \"nasal\", \"resp\"]\n",
    "#     )\n",
    "\n",
    "#     print(\"Resulting DataFrame shape:\", signal_df.shape)\n",
    "#     print(signal_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69e9f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 2. integer‐divide the row index by 48 000 to get a group ID\n",
    "group_id = np.arange(len(signal_df)) // 48000\n",
    "\n",
    "# 3. group & aggregate\n",
    "#    – numeric columns (e.g. Tracheal, Mic) will be averaged\n",
    "#    – if you have binary labels (nasal, resp) you probably want max()\n",
    "agg = signal_df.groupby(group_id).agg({\n",
    "    'Tracheal': 'mean',\n",
    "    'Mic':      'mean',\n",
    "    'nasal':    'max',\n",
    "    'resp':     'max',\n",
    "})\n",
    "\n",
    "# 4. (optional) reset the index so it’s back to 0,1,2…\n",
    "agg = agg.reset_index(drop=True)\n",
    "\n",
    "# 5. save\n",
    "agg.to_csv('signal_compressed_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd38dd10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signal_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msignal_df\u001b[49m.to_csv(\u001b[33m\"\u001b[39m\u001b[33msignal.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'signal_df' is not defined"
     ]
    }
   ],
   "source": [
    "signal_df.to_csv(\"signal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6856fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "signal_df = pd.read_csv('signal_compressed_total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d904bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nasal events (47 runs):\n",
      "  3934–3938  (0.082s → 0.082s)\n",
      "  4053–4063  (0.084s → 0.085s)\n",
      "  4107–4112  (0.086s → 0.086s)\n",
      "  4113–4123  (0.086s → 0.086s)\n",
      "  5342–5347  (0.111s → 0.111s)\n",
      "  5389–5398  (0.112s → 0.112s)\n",
      "  5414–5422  (0.113s → 0.113s)\n",
      "  5437–5441  (0.113s → 0.113s)\n",
      "  5490–5494  (0.114s → 0.114s)\n",
      "  5964–5969  (0.124s → 0.124s)\n",
      "  5998–6003  (0.125s → 0.125s)\n",
      "  6061–6068  (0.126s → 0.126s)\n",
      "  6070–6074  (0.126s → 0.127s)\n",
      "  6082–6087  (0.127s → 0.127s)\n",
      "  6128–6132  (0.128s → 0.128s)\n",
      "  6142–6150  (0.128s → 0.128s)\n",
      "  6200–6208  (0.129s → 0.129s)\n",
      "  6249–6253  (0.130s → 0.130s)\n",
      "  6282–6295  (0.131s → 0.131s)\n",
      "  6314–6318  (0.132s → 0.132s)\n",
      "  6334–6341  (0.132s → 0.132s)\n",
      "  6404–6408  (0.133s → 0.134s)\n",
      "  6419–6430  (0.134s → 0.134s)\n",
      "  6436–6440  (0.134s → 0.134s)\n",
      "  6446–6451  (0.134s → 0.134s)\n",
      "  6456–6461  (0.135s → 0.135s)\n",
      "  6477–6513  (0.135s → 0.136s)\n",
      "  6519–6552  (0.136s → 0.137s)\n",
      "  6558–6606  (0.137s → 0.138s)\n",
      "  6612–6622  (0.138s → 0.138s)\n",
      "  6628–6632  (0.138s → 0.138s)\n",
      "  6638–6645  (0.138s → 0.138s)\n",
      "  6650–6706  (0.139s → 0.140s)\n",
      "  6712–6719  (0.140s → 0.140s)\n",
      "  6725–6737  (0.140s → 0.140s)\n",
      "  6742–6775  (0.140s → 0.141s)\n",
      "  6776–6804  (0.141s → 0.142s)\n",
      "  6810–6814  (0.142s → 0.142s)\n",
      "  6828–6836  (0.142s → 0.142s)\n",
      "  6842–6847  (0.143s → 0.143s)\n",
      "  6848–6853  (0.143s → 0.143s)\n",
      "  6891–6909  (0.144s → 0.144s)\n",
      "  9513–9522  (0.198s → 0.198s)\n",
      "  9619–9631  (0.200s → 0.201s)\n",
      "  9992–9997  (0.208s → 0.208s)\n",
      "  10353–10357  (0.216s → 0.216s)\n",
      "  13884–13889  (0.289s → 0.289s)\n",
      "\n",
      "resp events (221 runs):\n",
      "  3752–3763  (0.078s → 0.078s)\n",
      "  3783–3795  (0.079s → 0.079s)\n",
      "  3813–3824  (0.079s → 0.080s)\n",
      "  3842–3852  (0.080s → 0.080s)\n",
      "  3878–3889  (0.081s → 0.081s)\n",
      "  3908–3921  (0.081s → 0.082s)\n",
      "  4017–4028  (0.084s → 0.084s)\n",
      "  4242–4252  (0.088s → 0.089s)\n",
      "  4263–4273  (0.089s → 0.089s)\n",
      "  4405–4417  (0.092s → 0.092s)\n",
      "  4459–4471  (0.093s → 0.093s)\n",
      "  4483–4494  (0.093s → 0.094s)\n",
      "  4503–4514  (0.094s → 0.094s)\n",
      "  4540–4552  (0.095s → 0.095s)\n",
      "  4574–4585  (0.095s → 0.096s)\n",
      "  4600–4610  (0.096s → 0.096s)\n",
      "  4623–4635  (0.096s → 0.097s)\n",
      "  4655–4666  (0.097s → 0.097s)\n",
      "  4698–4708  (0.098s → 0.098s)\n",
      "  4766–4778  (0.099s → 0.100s)\n",
      "  4869–4881  (0.101s → 0.102s)\n",
      "  4895–4908  (0.102s → 0.102s)\n",
      "  5046–5057  (0.105s → 0.105s)\n",
      "  5095–5107  (0.106s → 0.106s)\n",
      "  5120–5131  (0.107s → 0.107s)\n",
      "  5399–5410  (0.112s → 0.113s)\n",
      "  5422–5434  (0.113s → 0.113s)\n",
      "  5442–5454  (0.113s → 0.114s)\n",
      "  5567–5577  (0.116s → 0.116s)\n",
      "  5589–5600  (0.116s → 0.117s)\n",
      "  5610–5621  (0.117s → 0.117s)\n",
      "  5634–5647  (0.117s → 0.118s)\n",
      "  5660–5670  (0.118s → 0.118s)\n",
      "  5739–5750  (0.120s → 0.120s)\n",
      "  5759–5770  (0.120s → 0.120s)\n",
      "  6064–6075  (0.126s → 0.127s)\n",
      "  6151–6162  (0.128s → 0.128s)\n",
      "  6261–6273  (0.130s → 0.131s)\n",
      "  6335–6347  (0.132s → 0.132s)\n",
      "  6362–6374  (0.133s → 0.133s)\n",
      "  6666–6677  (0.139s → 0.139s)\n",
      "  6792–6804  (0.141s → 0.142s)\n",
      "  6812–6824  (0.142s → 0.142s)\n",
      "  6851–6863  (0.143s → 0.143s)\n",
      "  6878–6890  (0.143s → 0.144s)\n",
      "  7028–7041  (0.146s → 0.147s)\n",
      "  7416–7428  (0.154s → 0.155s)\n",
      "  7518–7530  (0.157s → 0.157s)\n",
      "  7592–7604  (0.158s → 0.158s)\n",
      "  7625–7636  (0.159s → 0.159s)\n",
      "  7645–7657  (0.159s → 0.160s)\n",
      "  7673–7687  (0.160s → 0.160s)\n",
      "  7883–7895  (0.164s → 0.164s)\n",
      "  8092–8103  (0.169s → 0.169s)\n",
      "  8130–8142  (0.169s → 0.170s)\n",
      "  8183–8194  (0.170s → 0.171s)\n",
      "  8217–8227  (0.171s → 0.171s)\n",
      "  8359–8372  (0.174s → 0.174s)\n",
      "  8394–8407  (0.175s → 0.175s)\n",
      "  8462–8472  (0.176s → 0.176s)\n",
      "  8512–8522  (0.177s → 0.178s)\n",
      "  8576–8587  (0.179s → 0.179s)\n",
      "  8695–8708  (0.181s → 0.181s)\n",
      "  8723–8734  (0.182s → 0.182s)\n",
      "  8752–8764  (0.182s → 0.183s)\n",
      "  8777–8789  (0.183s → 0.183s)\n",
      "  8808–8821  (0.183s → 0.184s)\n",
      "  8830–8841  (0.184s → 0.184s)\n",
      "  8964–8976  (0.187s → 0.187s)\n",
      "  9003–9017  (0.188s → 0.188s)\n",
      "  9041–9055  (0.188s → 0.189s)\n",
      "  9104–9123  (0.190s → 0.190s)\n",
      "  9669–9680  (0.201s → 0.202s)\n",
      "  9692–9703  (0.202s → 0.202s)\n",
      "  9729–9740  (0.203s → 0.203s)\n",
      "  9776–9787  (0.204s → 0.204s)\n",
      "  10012–10023  (0.209s → 0.209s)\n",
      "  10033–10043  (0.209s → 0.209s)\n",
      "  10685–10698  (0.223s → 0.223s)\n",
      "  10763–10775  (0.224s → 0.224s)\n",
      "  10810–10821  (0.225s → 0.225s)\n",
      "  10909–10920  (0.227s → 0.228s)\n",
      "  11084–11096  (0.231s → 0.231s)\n",
      "  11175–11188  (0.233s → 0.233s)\n",
      "  11310–11322  (0.236s → 0.236s)\n",
      "  11361–11372  (0.237s → 0.237s)\n",
      "  11401–11411  (0.238s → 0.238s)\n",
      "  11457–11468  (0.239s → 0.239s)\n",
      "  11705–11717  (0.244s → 0.244s)\n",
      "  11738–11749  (0.245s → 0.245s)\n",
      "  11804–11815  (0.246s → 0.246s)\n",
      "  11829–11839  (0.246s → 0.247s)\n",
      "  11857–11869  (0.247s → 0.247s)\n",
      "  11894–11905  (0.248s → 0.248s)\n",
      "  11912–11927  (0.248s → 0.248s)\n",
      "  11953–11964  (0.249s → 0.249s)\n",
      "  12011–12023  (0.250s → 0.250s)\n",
      "  12069–12081  (0.251s → 0.252s)\n",
      "  12169–12181  (0.254s → 0.254s)\n",
      "  12215–12225  (0.254s → 0.255s)\n",
      "  12243–12255  (0.255s → 0.255s)\n",
      "  12271–12282  (0.256s → 0.256s)\n",
      "  12303–12315  (0.256s → 0.257s)\n",
      "  12352–12364  (0.257s → 0.258s)\n",
      "  12391–12403  (0.258s → 0.258s)\n",
      "  12438–12451  (0.259s → 0.259s)\n",
      "  12481–12497  (0.260s → 0.260s)\n",
      "  12520–12532  (0.261s → 0.261s)\n",
      "  12560–12571  (0.262s → 0.262s)\n",
      "  12873–12884  (0.268s → 0.268s)\n",
      "  13018–13030  (0.271s → 0.271s)\n",
      "  13041–13052  (0.272s → 0.272s)\n",
      "  13065–13078  (0.272s → 0.272s)\n",
      "  13232–13245  (0.276s → 0.276s)\n",
      "  13269–13283  (0.276s → 0.277s)\n",
      "  13334–13345  (0.278s → 0.278s)\n",
      "  13562–13573  (0.283s → 0.283s)\n",
      "  13585–13595  (0.283s → 0.283s)\n",
      "  13905–13916  (0.290s → 0.290s)\n",
      "  13965–13976  (0.291s → 0.291s)\n",
      "  13990–14002  (0.291s → 0.292s)\n",
      "  14058–14070  (0.293s → 0.293s)\n",
      "  14081–14093  (0.293s → 0.294s)\n",
      "  14105–14117  (0.294s → 0.294s)\n",
      "  14130–14141  (0.294s → 0.295s)\n",
      "  14154–14166  (0.295s → 0.295s)\n",
      "  14181–14193  (0.295s → 0.296s)\n",
      "  14208–14220  (0.296s → 0.296s)\n",
      "  14235–14247  (0.297s → 0.297s)\n",
      "  14262–14274  (0.297s → 0.297s)\n",
      "  14286–14296  (0.298s → 0.298s)\n",
      "  14311–14321  (0.298s → 0.298s)\n",
      "  14332–14343  (0.299s → 0.299s)\n",
      "  14356–14366  (0.299s → 0.299s)\n",
      "  14417–14428  (0.300s → 0.301s)\n",
      "  14443–14454  (0.301s → 0.301s)\n",
      "  14657–14668  (0.305s → 0.306s)\n",
      "  14717–14728  (0.307s → 0.307s)\n",
      "  14739–14750  (0.307s → 0.307s)\n",
      "  14832–14844  (0.309s → 0.309s)\n",
      "  14854–14865  (0.309s → 0.310s)\n",
      "  14881–14893  (0.310s → 0.310s)\n",
      "  14913–14925  (0.311s → 0.311s)\n",
      "  14936–14949  (0.311s → 0.311s)\n",
      "  14962–14973  (0.312s → 0.312s)\n",
      "  14996–15009  (0.312s → 0.313s)\n",
      "  15028–15040  (0.313s → 0.313s)\n",
      "  15053–15063  (0.314s → 0.314s)\n",
      "  15073–15086  (0.314s → 0.314s)\n",
      "  15098–15110  (0.315s → 0.315s)\n",
      "  15128–15140  (0.315s → 0.315s)\n",
      "  15152–15167  (0.316s → 0.316s)\n",
      "  15182–15194  (0.316s → 0.317s)\n",
      "  15209–15222  (0.317s → 0.317s)\n",
      "  15236–15249  (0.317s → 0.318s)\n",
      "  15263–15275  (0.318s → 0.318s)\n",
      "  15289–15300  (0.319s → 0.319s)\n",
      "  15311–15323  (0.319s → 0.319s)\n",
      "  15340–15353  (0.320s → 0.320s)\n",
      "  15370–15382  (0.320s → 0.320s)\n",
      "  15396–15408  (0.321s → 0.321s)\n",
      "  15421–15432  (0.321s → 0.322s)\n",
      "  15446–15459  (0.322s → 0.322s)\n",
      "  15472–15486  (0.322s → 0.323s)\n",
      "  15495–15511  (0.323s → 0.323s)\n",
      "  15523–15533  (0.323s → 0.324s)\n",
      "  15735–15748  (0.328s → 0.328s)\n",
      "  15769–15780  (0.329s → 0.329s)\n",
      "  15806–15820  (0.329s → 0.330s)\n",
      "  15837–15850  (0.330s → 0.330s)\n",
      "  15877–15891  (0.331s → 0.331s)\n",
      "  15928–15940  (0.332s → 0.332s)\n",
      "  15955–15968  (0.332s → 0.333s)\n",
      "  16026–16038  (0.334s → 0.334s)\n",
      "  16063–16076  (0.335s → 0.335s)\n",
      "  16088–16100  (0.335s → 0.335s)\n",
      "  16109–16121  (0.336s → 0.336s)\n",
      "  16141–16152  (0.336s → 0.337s)\n",
      "  16338–16349  (0.340s → 0.341s)\n",
      "  16362–16374  (0.341s → 0.341s)\n",
      "  16391–16402  (0.341s → 0.342s)\n",
      "  16412–16427  (0.342s → 0.342s)\n",
      "  16444–16459  (0.343s → 0.343s)\n",
      "  16471–16484  (0.343s → 0.343s)\n",
      "  16502–16515  (0.344s → 0.344s)\n",
      "  16531–16543  (0.344s → 0.345s)\n",
      "  16559–16571  (0.345s → 0.345s)\n",
      "  16584–16594  (0.345s → 0.346s)\n",
      "  16609–16621  (0.346s → 0.346s)\n",
      "  16636–16649  (0.347s → 0.347s)\n",
      "  16667–16678  (0.347s → 0.347s)\n",
      "  16693–16706  (0.348s → 0.348s)\n",
      "  16721–16733  (0.348s → 0.349s)\n",
      "  16751–16763  (0.349s → 0.349s)\n",
      "  16799–16812  (0.350s → 0.350s)\n",
      "  16823–16835  (0.350s → 0.351s)\n",
      "  16848–16866  (0.351s → 0.351s)\n",
      "  16885–16896  (0.352s → 0.352s)\n",
      "  16939–16952  (0.353s → 0.353s)\n",
      "  16972–16985  (0.354s → 0.354s)\n",
      "  17068–17080  (0.356s → 0.356s)\n",
      "  17099–17111  (0.356s → 0.356s)\n",
      "  17125–17136  (0.357s → 0.357s)\n",
      "  17150–17163  (0.357s → 0.358s)\n",
      "  17175–17189  (0.358s → 0.358s)\n",
      "  17198–17215  (0.358s → 0.359s)\n",
      "  17234–17245  (0.359s → 0.359s)\n",
      "  17267–17278  (0.360s → 0.360s)\n",
      "  17311–17324  (0.361s → 0.361s)\n",
      "  17357–17369  (0.362s → 0.362s)\n",
      "  17379–17391  (0.362s → 0.362s)\n",
      "  17404–17422  (0.363s → 0.363s)\n",
      "  17444–17462  (0.363s → 0.364s)\n",
      "  17495–17511  (0.364s → 0.365s)\n",
      "  17539–17561  (0.365s → 0.366s)\n",
      "  17586–17598  (0.366s → 0.367s)\n",
      "  17610–17620  (0.367s → 0.367s)\n",
      "  17642–17659  (0.368s → 0.368s)\n",
      "  17682–17701  (0.368s → 0.369s)\n",
      "  17820–17832  (0.371s → 0.371s)\n",
      "  17855–17867  (0.372s → 0.372s)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_mask_events(signal_df, mask_cols=(\"nasal\", \"resp\"), sr=48000):\n",
    "    \"\"\"\n",
    "    For each column in mask_cols, find the contiguous runs of 1's in signal_df[col].\n",
    "    Returns a dict mapping col → list of intervals, where each interval is a dict:\n",
    "      {\n",
    "        \"start_idx\": int,    # sample index where mask turns on\n",
    "        \"end_idx\":   int,    # sample index where mask turns off\n",
    "        \"start_time\": float, # seconds\n",
    "        \"end_time\":   float  # seconds\n",
    "      }\n",
    "    \"\"\"\n",
    "    events = {}\n",
    "    for col in mask_cols:\n",
    "        mask = signal_df[col].astype(bool).values\n",
    "        # diffs: +1 where 0→1,  -1 where 1→0\n",
    "        diff = np.diff(mask.astype(int))\n",
    "        starts = np.where(diff ==  1)[0] + 1\n",
    "        ends   = np.where(diff == -1)[0] + 1\n",
    "\n",
    "        # handle case where mask is already True at index 0\n",
    "        if mask[0]:\n",
    "            starts = np.insert(starts, 0, 0)\n",
    "        # handle case where mask stays True until the end\n",
    "        if mask[-1]:\n",
    "            ends = np.append(ends, len(mask))\n",
    "\n",
    "        intervals = []\n",
    "        for s, e in zip(starts, ends):\n",
    "            intervals.append({\n",
    "                \"start_idx\":  int(s),\n",
    "                \"end_idx\":    int(e),\n",
    "                \"start_time\": s / sr,\n",
    "                \"end_time\":   e / sr\n",
    "            })\n",
    "        events[col] = intervals\n",
    "    return events\n",
    "\n",
    "events = extract_mask_events(signal_df)\n",
    "\n",
    "# To print them:\n",
    "for col, ivals in events.items():\n",
    "    print(f\"\\n{col} events ({len(ivals)} runs):\")\n",
    "    for iv in ivals:\n",
    "        print(f\"  {iv['start_idx']}–{iv['end_idx']}  ({iv['start_time']:.3f}s → {iv['end_time']:.3f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3979547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3595    0\n",
      "3596    0\n",
      "3597    0\n",
      "3598    0\n",
      "3599    0\n",
      "Name: nasal_lbl, Length: 3600, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3595    0\n",
      "3596    0\n",
      "3597    0\n",
      "3598    0\n",
      "3599    0\n",
      "Name: resp_lbl, Length: 3600, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "signal_df['nasal_lbl'] = (signal_df['nasal'] > 0.5).astype('int64')\n",
    "signal_df['resp_lbl']  = (signal_df['resp']  > 0.5).astype('int64')\n",
    "\n",
    "print(signal_df['nasal_lbl'])\n",
    "print(signal_df['resp_lbl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean & std\n",
    "mean = signal_df['Tracheal'].mean()\n",
    "std  = signal_df['Tracheal'].std()\n",
    "\n",
    "# create a new, normalized column\n",
    "signal_df['Tracheal_z'] = (signal_df['Tracheal'] - mean) / std\n",
    "\n",
    "mean = signal_df['Mic'].mean()\n",
    "std  = signal_df['Mic'].std()\n",
    "\n",
    "# create a new, normalized column\n",
    "signal_df['Mic_z'] = (signal_df['Mic'] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801cb24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/50 | TrainN CE=0.7400 | TrainR CE=0.7141 | ValN CE=0.6948, Acc=2.9% | ValR CE=0.6933, Acc=14.9% | LRs=(1.00e-03, 1.00e-03)\n",
      "Epoch 02/50 | TrainN CE=0.6944 | TrainR CE=0.6933 | ValN CE=0.6940, Acc=10.4% | ValR CE=0.6932, Acc=20.5% | LRs=(1.00e-03, 1.00e-03)\n",
      "Epoch 03/50 | TrainN CE=0.6935 | TrainR CE=0.6932 | ValN CE=0.6933, Acc=6.6% | ValR CE=0.6942, Acc=14.9% | LRs=(1.00e-03, 1.00e-03)\n",
      "Epoch 04/50 | TrainN CE=0.6858 | TrainR CE=0.6925 | ValN CE=0.7086, Acc=2.9% | ValR CE=0.7281, Acc=14.9% | LRs=(1.00e-03, 1.00e-03)\n",
      "Epoch 05/50 | TrainN CE=0.6543 | TrainR CE=0.6914 | ValN CE=0.8168, Acc=2.9% | ValR CE=0.7092, Acc=14.9% | LRs=(1.00e-03, 1.00e-03)\n",
      "Epoch 06/50 | TrainN CE=0.6169 | TrainR CE=0.6903 | ValN CE=0.7803, Acc=26.2% | ValR CE=0.6960, Acc=85.1% | LRs=(1.00e-03, 1.00e-03)\n",
      "Epoch 07/50 | TrainN CE=0.5670 | TrainR CE=0.6888 | ValN CE=0.9957, Acc=2.9% | ValR CE=0.6932, Acc=14.9% | LRs=(1.00e-03, 5.00e-04)\n",
      "Epoch 08/50 | TrainN CE=0.5104 | TrainR CE=0.6848 | ValN CE=0.9018, Acc=4.7% | ValR CE=0.6970, Acc=83.7% | LRs=(1.00e-03, 5.00e-04)\n",
      "Epoch 09/50 | TrainN CE=0.4640 | TrainR CE=0.6812 | ValN CE=1.0056, Acc=4.5% | ValR CE=0.6941, Acc=80.9% | LRs=(5.00e-04, 5.00e-04)\n",
      "Epoch 10/50 | TrainN CE=0.3930 | TrainR CE=0.6780 | ValN CE=1.6812, Acc=97.1% | ValR CE=0.6976, Acc=82.3% | LRs=(5.00e-04, 5.00e-04)\n",
      "Epoch 11/50 | TrainN CE=0.3516 | TrainR CE=0.6726 | ValN CE=1.0753, Acc=86.7% | ValR CE=0.7068, Acc=80.9% | LRs=(5.00e-04, 5.00e-04)\n",
      "Epoch 12/50 | TrainN CE=0.3166 | TrainR CE=0.6636 | ValN CE=1.5426, Acc=82.0% | ValR CE=0.7223, Acc=82.3% | LRs=(5.00e-04, 5.00e-04)\n",
      "Epoch 13/50 | TrainN CE=0.2843 | TrainR CE=0.6412 | ValN CE=0.9631, Acc=46.9% | ValR CE=1.2644, Acc=83.7% | LRs=(5.00e-04, 2.50e-04)\n",
      "Epoch 14/50 | TrainN CE=0.2673 | TrainR CE=0.5880 | ValN CE=2.2553, Acc=94.1% | ValR CE=1.7979, Acc=79.9% | LRs=(5.00e-04, 2.50e-04)\n",
      "Epoch 15/50 | TrainN CE=0.2424 | TrainR CE=0.5411 | ValN CE=1.4252, Acc=78.9% | ValR CE=0.7777, Acc=59.7% | LRs=(2.50e-04, 2.50e-04)\n",
      "Epoch 16/50 | TrainN CE=0.2106 | TrainR CE=0.4970 | ValN CE=2.3640, Acc=87.4% | ValR CE=1.6672, Acc=78.9% | LRs=(2.50e-04, 2.50e-04)\n",
      "Epoch 17/50 | TrainN CE=0.1892 | TrainR CE=0.4593 | ValN CE=2.2722, Acc=81.4% | ValR CE=1.6158, Acc=74.1% | LRs=(2.50e-04, 2.50e-04)\n",
      "Epoch 18/50 | TrainN CE=0.1770 | TrainR CE=0.4194 | ValN CE=1.8552, Acc=77.6% | ValR CE=2.9603, Acc=82.1% | LRs=(2.50e-04, 2.50e-04)\n",
      "Epoch 19/50 | TrainN CE=0.1685 | TrainR CE=0.3803 | ValN CE=3.0584, Acc=90.2% | ValR CE=1.4497, Acc=64.2% | LRs=(2.50e-04, 1.25e-04)\n",
      "Epoch 20/50 | TrainN CE=0.1537 | TrainR CE=0.3262 | ValN CE=3.1911, Acc=88.9% | ValR CE=2.6203, Acc=79.0% | LRs=(2.50e-04, 1.25e-04)\n",
      "Epoch 21/50 | TrainN CE=0.1403 | TrainR CE=0.2859 | ValN CE=2.4823, Acc=78.1% | ValR CE=2.2378, Acc=77.7% | LRs=(1.25e-04, 1.25e-04)\n",
      "Epoch 22/50 | TrainN CE=0.1265 | TrainR CE=0.2480 | ValN CE=3.3877, Acc=88.5% | ValR CE=2.5147, Acc=79.3% | LRs=(1.25e-04, 1.25e-04)\n",
      "Epoch 23/50 | TrainN CE=0.1193 | TrainR CE=0.2116 | ValN CE=3.1875, Acc=87.7% | ValR CE=3.0245, Acc=83.1% | LRs=(1.25e-04, 1.25e-04)\n",
      "Epoch 24/50 | TrainN CE=0.1122 | TrainR CE=0.1797 | ValN CE=3.5426, Acc=90.3% | ValR CE=3.0683, Acc=82.2% | LRs=(1.25e-04, 1.25e-04)\n",
      "Epoch 25/50 | TrainN CE=0.1085 | TrainR CE=0.1535 | ValN CE=3.3466, Acc=87.7% | ValR CE=3.3195, Acc=82.9% | LRs=(1.25e-04, 6.25e-05)\n",
      "Epoch 26/50 | TrainN CE=0.1034 | TrainR CE=0.1260 | ValN CE=3.5100, Acc=88.6% | ValR CE=2.7237, Acc=79.0% | LRs=(1.25e-04, 6.25e-05)\n",
      "Epoch 27/50 | TrainN CE=0.1002 | TrainR CE=0.1114 | ValN CE=3.4586, Acc=89.9% | ValR CE=2.8652, Acc=80.5% | LRs=(6.25e-05, 6.25e-05)\n",
      "Epoch 28/50 | TrainN CE=0.0920 | TrainR CE=0.1045 | ValN CE=3.8581, Acc=90.4% | ValR CE=2.5154, Acc=77.7% | LRs=(6.25e-05, 6.25e-05)\n",
      "Epoch 29/50 | TrainN CE=0.0893 | TrainR CE=0.0966 | ValN CE=3.8521, Acc=90.9% | ValR CE=2.2715, Acc=76.3% | LRs=(6.25e-05, 6.25e-05)\n",
      "Epoch 30/50 | TrainN CE=0.0876 | TrainR CE=0.0905 | ValN CE=3.9182, Acc=91.0% | ValR CE=2.7020, Acc=79.5% | LRs=(6.25e-05, 6.25e-05)\n",
      "Epoch 31/50 | TrainN CE=0.0846 | TrainR CE=0.0860 | ValN CE=3.9629, Acc=91.0% | ValR CE=2.6155, Acc=79.1% | LRs=(6.25e-05, 3.13e-05)\n",
      "Epoch 32/50 | TrainN CE=0.0828 | TrainR CE=0.0781 | ValN CE=4.1187, Acc=91.1% | ValR CE=2.1828, Acc=73.4% | LRs=(6.25e-05, 3.13e-05)\n",
      "Epoch 33/50 | TrainN CE=0.0801 | TrainR CE=0.0758 | ValN CE=3.9985, Acc=90.3% | ValR CE=2.2651, Acc=72.9% | LRs=(3.13e-05, 3.13e-05)\n",
      "Epoch 34/50 | TrainN CE=0.0778 | TrainR CE=0.0729 | ValN CE=4.0108, Acc=90.9% | ValR CE=2.3155, Acc=75.1% | LRs=(3.13e-05, 3.13e-05)\n",
      "Epoch 35/50 | TrainN CE=0.0760 | TrainR CE=0.0712 | ValN CE=4.1500, Acc=90.6% | ValR CE=2.1687, Acc=74.1% | LRs=(3.13e-05, 3.13e-05)\n",
      "Epoch 36/50 | TrainN CE=0.0750 | TrainR CE=0.0696 | ValN CE=4.1483, Acc=91.3% | ValR CE=2.1798, Acc=75.9% | LRs=(3.13e-05, 3.13e-05)\n",
      "Epoch 37/50 | TrainN CE=0.0736 | TrainR CE=0.0677 | ValN CE=4.2820, Acc=90.5% | ValR CE=2.2455, Acc=73.3% | LRs=(3.13e-05, 1.56e-05)\n",
      "Epoch 38/50 | TrainN CE=0.0737 | TrainR CE=0.0646 | ValN CE=4.2502, Acc=90.8% | ValR CE=2.0649, Acc=73.1% | LRs=(3.13e-05, 1.56e-05)\n",
      "Epoch 39/50 | TrainN CE=0.0729 | TrainR CE=0.0635 | ValN CE=4.2973, Acc=90.9% | ValR CE=2.1062, Acc=73.6% | LRs=(1.56e-05, 1.56e-05)\n",
      "Epoch 40/50 | TrainN CE=0.0700 | TrainR CE=0.0622 | ValN CE=4.2851, Acc=90.9% | ValR CE=2.1289, Acc=72.4% | LRs=(1.56e-05, 1.56e-05)\n",
      "Epoch 41/50 | TrainN CE=0.0683 | TrainR CE=0.0621 | ValN CE=4.4417, Acc=91.2% | ValR CE=2.1287, Acc=74.4% | LRs=(1.56e-05, 1.56e-05)\n",
      "Epoch 42/50 | TrainN CE=0.0697 | TrainR CE=0.0613 | ValN CE=4.3164, Acc=90.9% | ValR CE=2.1620, Acc=73.3% | LRs=(1.56e-05, 1.56e-05)\n",
      "Epoch 43/50 | TrainN CE=0.0687 | TrainR CE=0.0601 | ValN CE=4.4012, Acc=91.5% | ValR CE=2.1596, Acc=73.7% | LRs=(1.56e-05, 7.81e-06)\n",
      "Epoch 44/50 | TrainN CE=0.0680 | TrainR CE=0.0593 | ValN CE=4.3660, Acc=91.2% | ValR CE=2.2313, Acc=73.2% | LRs=(1.56e-05, 7.81e-06)\n",
      "Epoch 45/50 | TrainN CE=0.0668 | TrainR CE=0.0580 | ValN CE=4.3830, Acc=91.1% | ValR CE=2.2139, Acc=73.4% | LRs=(7.81e-06, 7.81e-06)\n",
      "Epoch 46/50 | TrainN CE=0.0665 | TrainR CE=0.0585 | ValN CE=4.3745, Acc=90.9% | ValR CE=2.1613, Acc=73.4% | LRs=(7.81e-06, 7.81e-06)\n",
      "Epoch 47/50 | TrainN CE=0.0671 | TrainR CE=0.0571 | ValN CE=4.4128, Acc=91.3% | ValR CE=2.2584, Acc=73.3% | LRs=(7.81e-06, 7.81e-06)\n",
      "Epoch 48/50 | TrainN CE=0.0666 | TrainR CE=0.0577 | ValN CE=4.4309, Acc=91.1% | ValR CE=2.2267, Acc=73.8% | LRs=(7.81e-06, 7.81e-06)\n",
      "Epoch 49/50 | TrainN CE=0.0662 | TrainR CE=0.0564 | ValN CE=4.4458, Acc=91.4% | ValR CE=2.2288, Acc=73.7% | LRs=(7.81e-06, 3.91e-06)\n",
      "Epoch 50/50 | TrainN CE=0.0654 | TrainR CE=0.0565 | ValN CE=4.4765, Acc=91.2% | ValR CE=2.2359, Acc=73.5% | LRs=(7.81e-06, 3.91e-06)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ─── 0. Load & preprocess CSV ───────────────────────────────────────────────\n",
    "df = pd.read_csv(\"signal_compressed_total.csv\")\n",
    "\n",
    "df['nasal_lbl'] = (df['nasal'] > 0.5).astype('int64')\n",
    "df['resp_lbl']  = (df['resp']  > 0.5).astype('int64')\n",
    "\n",
    "# ─── 1. 80/20 split ─────────────────────────────────────────────────────────\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42,\n",
    "    stratify=df['nasal_lbl']\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop=True)\n",
    "\n",
    "# ─── 2. Dataset ──────────────────────────────────────────────────────────────\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, df, seq_len):\n",
    "        self.X       = df.iloc[:, :2].values.astype('float32')\n",
    "        self.nasal   = df['nasal_lbl'].values.astype('int64')\n",
    "        self.resp    = df['resp_lbl'].values.astype('int64')\n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return max(len(self.X) - self.seq_len, 0)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx:idx+self.seq_len]\n",
    "        n = self.nasal[idx:idx+self.seq_len]\n",
    "        r = self.resp[idx:idx+self.seq_len]\n",
    "        return torch.from_numpy(x), torch.from_numpy(n), torch.from_numpy(r)\n",
    "\n",
    "\n",
    "# ─── 3. Single‐task CNN+GRU ──────────────────────────────────────────────────\n",
    "class CNN_GRU_Single(nn.Module):\n",
    "    def __init__(self, input_dim=2, cnn_hidden=256, cnn_layers=16, kernel_size=3,\n",
    "                 gru_hidden=256, gru_layers=16, bidirectional=True, num_classes=2):\n",
    "        super().__init__()\n",
    "        # CNN\n",
    "        blocks, in_ch = [], input_dim\n",
    "        for _ in range(cnn_layers):\n",
    "            blocks += [\n",
    "                nn.Conv1d(in_ch, cnn_hidden, kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm1d(cnn_hidden),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.1),\n",
    "            ]\n",
    "            in_ch = cnn_hidden\n",
    "        self.cnn = nn.Sequential(*blocks)\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            cnn_hidden, gru_hidden, gru_layers,\n",
    "            batch_first=True, bidirectional=bidirectional\n",
    "        )\n",
    "        out_dim = gru_hidden * (2 if bidirectional else 1)\n",
    "        self.head = nn.Linear(out_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        h = x.permute(0,2,1)      # (B,2,T)\n",
    "        h = self.cnn(h)           # (B,cnn_hidden,T)\n",
    "        h = h.permute(0,2,1)      # (B,T,cnn_hidden)\n",
    "        o, _ = self.gru(h)        # (B,T,out_dim)\n",
    "        return self.head(o)       # (B,T,2)\n",
    "\n",
    "\n",
    "# ─── 4. Hyperparams & loaders ───────────────────────────────────────────────\n",
    "seq_len    = 50\n",
    "batch_sz   = 256\n",
    "lr         = 1e-3\n",
    "n_epochs   = 50\n",
    "device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_ds = SignalDataset(train_df, seq_len)\n",
    "val_ds   = SignalDataset(val_df,   seq_len)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_sz, shuffle=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_sz, shuffle=False,drop_last=False)\n",
    "\n",
    "# ─── 5. Instantiate two models ──────────────────────────────────────────────\n",
    "nasal_model = CNN_GRU_Single().to(device).float()\n",
    "resp_model  = CNN_GRU_Single().to(device).float()\n",
    "nasal_model.train(); resp_model.train()\n",
    "# compute base class‐imbalance weights on training split\n",
    "n_counts = np.bincount(train_df['nasal_lbl'])\n",
    "r_counts = np.bincount(train_df['resp_lbl'])\n",
    "base_w_n = torch.tensor([(n_counts.sum()/(2*n_counts[i])) for i in [0,1]],\n",
    "                        device=device)\n",
    "base_w_r = torch.tensor([(r_counts.sum()/(2*r_counts[i])) for i in [0,1]],\n",
    "                        device=device)\n",
    "\n",
    "# ─── NEW: punish missing events with extra penalty ─────────────────────────\n",
    "penalty_n = 1   # weight multiplier for missed nasal events\n",
    "penalty_r = 1   # weight multiplier for missed resp events\n",
    "\n",
    "w_n = base_w_n.clone().float()\n",
    "w_r = base_w_r.clone().float()\n",
    "# amplify the positive‐class (index=1) weight\n",
    "w_n[1] *= penalty_n\n",
    "w_r[1] *= penalty_r\n",
    "\n",
    "criterion_n = nn.CrossEntropyLoss(weight=w_n)\n",
    "criterion_r = nn.CrossEntropyLoss(weight=w_r)\n",
    "\n",
    "opt_n = torch.optim.Adam(nasal_model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "opt_r = torch.optim.Adam(resp_model.parameters(),  lr=lr, weight_decay=1e-4)\n",
    "sched_n = ReduceLROnPlateau(opt_n, mode='min', factor=0.5, patience=5)\n",
    "sched_r = ReduceLROnPlateau(opt_r, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# ─── 6. Training & validation ───────────────────────────────────────────────\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # ─── TRAIN ────────────────────────────────────────\n",
    "    nasal_model.train()\n",
    "    resp_model.train()\n",
    "    train_n_loss = train_r_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for x_b, n_b, r_b in train_loader:\n",
    "        B, T, _ = x_b.shape\n",
    "        x = x_b.to(device).float()\n",
    "        n = n_b.to(device)\n",
    "        r = r_b.to(device)\n",
    "\n",
    "        # nasal branch\n",
    "        ln = nasal_model(x)  # (B,T,2)\n",
    "        loss_n = criterion_n(ln.reshape(-1,2), n.reshape(-1))\n",
    "        opt_n.zero_grad()\n",
    "        loss_n.backward()\n",
    "        nn.utils.clip_grad_norm_(nasal_model.parameters(), 0.5)\n",
    "        opt_n.step()\n",
    "\n",
    "        # resp branch\n",
    "        lr_ = resp_model(x)\n",
    "        loss_r = criterion_r(lr_.reshape(-1,2), r.reshape(-1))\n",
    "        opt_r.zero_grad()\n",
    "        loss_r.backward()\n",
    "        nn.utils.clip_grad_norm_(resp_model.parameters(), 0.5)\n",
    "        opt_r.step()\n",
    "\n",
    "        train_n_loss += loss_n.item() * B * T\n",
    "        train_r_loss += loss_r.item() * B * T\n",
    "        total        += B * T\n",
    "\n",
    "    train_n_loss /= total\n",
    "    train_r_loss /= total\n",
    "\n",
    "    # ─── VALIDATION ────────────────────────────────────\n",
    "    nasal_model.eval()\n",
    "    resp_model.eval()\n",
    "    val_n_loss = val_r_loss = 0.0\n",
    "    vtotal = 0\n",
    "\n",
    "    # for accuracy\n",
    "    correct_n = correct_r = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_b, n_b, r_b in val_loader:\n",
    "            B, T, _ = x_b.shape\n",
    "            x = x_b.to(device).float()\n",
    "            n = n_b.to(device)\n",
    "            r = r_b.to(device)\n",
    "\n",
    "            ln = nasal_model(x)    # (B,T,2)\n",
    "            lr_ = resp_model(x)\n",
    "\n",
    "            # accumulate loss\n",
    "            val_n_loss += criterion_n(ln.reshape(-1,2), n.reshape(-1)).item() * B * T\n",
    "            val_r_loss += criterion_r(lr_.reshape(-1,2), r.reshape(-1)).item() * B * T\n",
    "            vtotal    += B * T\n",
    "\n",
    "            # accumulate correct predictions\n",
    "            preds_n = ln.argmax(-1)   # (B,T)\n",
    "            preds_r = lr_.argmax(-1)\n",
    "            correct_n += (preds_n == n).sum().item()\n",
    "            correct_r += (preds_r == r).sum().item()\n",
    "\n",
    "    val_n_loss /= vtotal\n",
    "    val_r_loss /= vtotal\n",
    "\n",
    "    # compute accuracy\n",
    "    val_n_acc = correct_n / vtotal * 100\n",
    "    val_r_acc = correct_r / vtotal * 100\n",
    "\n",
    "    # scheduler step on validation loss\n",
    "    sched_n.step(val_n_loss)\n",
    "    sched_r.step(val_r_loss)\n",
    "\n",
    "    lr_n = opt_n.param_groups[0]['lr']\n",
    "    lr_r = opt_r.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{n_epochs} | \"\n",
    "        f\"TrainN CE={train_n_loss:.4f} | TrainR CE={train_r_loss:.4f} | \"\n",
    "        f\"ValN CE={val_n_loss:.4f}, Acc={val_n_acc:.1f}% | \"\n",
    "        f\"ValR CE={val_r_loss:.4f}, Acc={val_r_acc:.1f}% | \"\n",
    "        f\"LRs=({lr_n:.2e}, {lr_r:.2e})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae88a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Load your CSV\n",
    "df_inf = pd.read_csv(\"signal_compressed_total.csv\")\n",
    "\n",
    "# 2) A dataset that only returns the feature windows\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, seq_len: int):\n",
    "        self.X       = df.iloc[:, 0:2].values.astype('float32')  # Tracheal & Mic\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.X) - self.seq_len + 1, 0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq = self.X[idx : idx + self.seq_len]                 # (seq_len, 2)\n",
    "        return torch.from_numpy(x_seq)\n",
    "\n",
    "# 3) Build DataLoader\n",
    "seq_len  = 50\n",
    "batch_sz = 256\n",
    "inf_ds    = InferenceDataset(df_inf, seq_len)\n",
    "inf_loader = DataLoader(inf_ds, batch_size=batch_sz, shuffle=False, drop_last=False)\n",
    "\n",
    "# 4) Run inference\n",
    "nasal_model.eval()\n",
    "resp_model.eval()\n",
    "\n",
    "all_preds_n, all_preds_r = [], []\n",
    "with torch.no_grad():\n",
    "    for x_batch in inf_loader:\n",
    "        x = x_batch.to(device).float()         # (B, seq_len, 2)\n",
    "        ln = nasal_model(x)                   # (B, seq_len, 2)\n",
    "        lr = resp_model(x)                    # (B, seq_len, 2)\n",
    "        all_preds_n.append(ln.argmax(-1).cpu())  \n",
    "        all_preds_r.append(lr.argmax(-1).cpu())\n",
    "\n",
    "# 5) Concatenate & flatten to length N\n",
    "pred_n = torch.cat(all_preds_n, dim=0).reshape(-1).numpy()[:len(df_inf)]\n",
    "pred_r = torch.cat(all_preds_r, dim=0).reshape(-1).numpy()[:len(df_inf)]\n",
    "\n",
    "# 6) Attach back and save\n",
    "df_inf['pred_nasal'] = pred_n\n",
    "df_inf['pred_resp']  = pred_r\n",
    "df_inf.to_csv(\"signal_with_preds.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd11c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nasal  Accuracy: 0.932\n",
      "Respir Accuracy: 0.739\n"
     ]
    }
   ],
   "source": [
    "# 1) Load & binarize your ground‐truth\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ─── 0. Load & preprocess CSV ───────────────────────────────────────────────\n",
    "df = pd.read_csv(\"signal_compressed_total.csv\")\n",
    "\n",
    "df['nasal_lbl'] = (df['nasal'] > 0.5).astype('int64')\n",
    "df['resp_lbl']  = (df['resp']  > 0.5).astype('int64')\n",
    "\n",
    "# ─── 1. 80/20 split ─────────────────────────────────────────────────────────\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42,\n",
    "    stratify=df['nasal_lbl']\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop=True)\n",
    "\n",
    "# ─── 2. Dataset ──────────────────────────────────────────────────────────────\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, df, seq_len):\n",
    "        self.X       = df.iloc[:, :2].values.astype('float32')\n",
    "        self.nasal   = df['nasal_lbl'].values.astype('int64')\n",
    "        self.resp    = df['resp_lbl'].values.astype('int64')\n",
    "        self.seq_len = seq_len\n",
    "    def __len__(self):\n",
    "        return max(len(self.X) - self.seq_len, 0)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx:idx+self.seq_len]\n",
    "        n = self.nasal[idx:idx+self.seq_len]\n",
    "        r = self.resp[idx:idx+self.seq_len]\n",
    "        return torch.from_numpy(x), torch.from_numpy(n), torch.from_numpy(r)\n",
    "\n",
    "\n",
    "# ─── 3. Single‐task CNN+GRU ──────────────────────────────────────────────────\n",
    "class CNN_GRU_Single(nn.Module):\n",
    "    def __init__(self, input_dim=2, cnn_hidden=256, cnn_layers=16, kernel_size=3,\n",
    "                 gru_hidden=256, gru_layers=16, bidirectional=True, num_classes=2):\n",
    "        super().__init__()\n",
    "        # CNN\n",
    "        blocks, in_ch = [], input_dim\n",
    "        for _ in range(cnn_layers):\n",
    "            blocks += [\n",
    "                nn.Conv1d(in_ch, cnn_hidden, kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm1d(cnn_hidden),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.1),\n",
    "            ]\n",
    "            in_ch = cnn_hidden\n",
    "        self.cnn = nn.Sequential(*blocks)\n",
    "        # GRU\n",
    "        self.gru = nn.GRU(\n",
    "            cnn_hidden, gru_hidden, gru_layers,\n",
    "            batch_first=True, bidirectional=bidirectional\n",
    "        )\n",
    "        out_dim = gru_hidden * (2 if bidirectional else 1)\n",
    "        self.head = nn.Linear(out_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        h = x.permute(0,2,1)      # (B,2,T)\n",
    "        h = self.cnn(h)           # (B,cnn_hidden,T)\n",
    "        h = h.permute(0,2,1)      # (B,T,cnn_hidden)\n",
    "        o, _ = self.gru(h)        # (B,T,out_dim)\n",
    "        return self.head(o)       # (B,T,2)\n",
    "\n",
    "device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "nasal_model = CNN_GRU_Single().to(device).float()\n",
    "resp_model  = CNN_GRU_Single().to(device).float()\n",
    "\n",
    "nasal_model.load_state_dict(torch.load(\"nasal_model.pth\", map_location=device))\n",
    "resp_model .load_state_dict(torch.load(\"resp_model.pth\",  map_location=device))\n",
    "\n",
    "df_inf = pd.read_csv(\"signal_compressed_total.csv\")\n",
    "df_inf['nasal_lbl'] = (df_inf['nasal'] > 0.5).astype('int64')\n",
    "df_inf['resp_lbl']  = (df_inf['resp'] > 0.5).astype('int64')\n",
    "\n",
    "# 2) Reuse your original SignalDataset (which expects nasal_lbl & resp_lbl)\n",
    "inf_ds    = SignalDataset(df_inf, seq_len=50)\n",
    "inf_loader = DataLoader(inf_ds, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "# 3) Run exactly as before:\n",
    "nasal_model.eval(); resp_model.eval()\n",
    "all_preds_n, all_preds_r = [], []\n",
    "with torch.no_grad():\n",
    "    for x_batch, _, _ in inf_loader:\n",
    "        x = x_batch.to(device).float()\n",
    "        ln = nasal_model(x); lr = resp_model(x)\n",
    "        all_preds_n.append(ln.argmax(-1).cpu())\n",
    "        all_preds_r.append(lr.argmax(-1).cpu())\n",
    "\n",
    "pred_n = torch.cat(all_preds_n, dim=0).reshape(-1).numpy()[:len(df_inf)]\n",
    "pred_r = torch.cat(all_preds_r, dim=0).reshape(-1).numpy()[:len(df_inf)]\n",
    "\n",
    "df_inf['pred_nasal'] = pred_n\n",
    "df_inf['pred_resp']  = pred_r\n",
    "\n",
    "# 4) Evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_n = accuracy_score(df_inf['nasal_lbl'], df_inf['pred_nasal'])\n",
    "acc_r = accuracy_score(df_inf['resp_lbl'],  df_inf['pred_resp'])\n",
    "print(f\"Nasal  Accuracy: {acc_n:.3f}\")\n",
    "print(f\"Respir Accuracy: {acc_r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3743dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nasal_model.state_dict(), \"nasal_model.pth\")\n",
    "torch.save(resp_model .state_dict(), \"resp_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hacktech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
